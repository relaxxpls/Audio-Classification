{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Audio Classification\r\n",
    "\r\n",
    "* Load model\r\n",
    "* Classify test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torchaudio\r\n",
    "import torchaudio.transforms as aT\r\n",
    "import torchvision.models as models\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class DenseNet(nn.Module):\r\n",
    "    def __init__(self, num_classes):\r\n",
    "        super().__init__()\r\n",
    "\r\n",
    "        self.model = models.densenet201(pretrained=True)\r\n",
    "        conv0 = self.model.features.conv0\r\n",
    "        self.model.features.conv0 = nn.Conv2d(\r\n",
    "            1,\r\n",
    "            conv0.out_channels,\r\n",
    "            kernel_size=conv0.kernel_size,\r\n",
    "            stride=conv0.stride,\r\n",
    "            padding=conv0.padding,\r\n",
    "        )\r\n",
    "        self.model.classifier = nn.Linear(1920, num_classes)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        output = self.model(x)\r\n",
    "        return output\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "print(device)\r\n",
    "\r\n",
    "original_rate = 44100\r\n",
    "sample_rate = 22050\r\n",
    "classes = ['1', '2', '3', '4', '5', '6', '7']\r\n",
    "\r\n",
    "def audio_loader(path, max_length_in_seconds=4):\r\n",
    "    waveform, sample_rate = torchaudio.load(path)\r\n",
    "    num_channels, num_frames = waveform.shape\r\n",
    "    max_frames = sample_rate * max_length_in_seconds\r\n",
    "\r\n",
    "    # ? Pad audio with zeros if too short or cut audio if too long\r\n",
    "    if num_frames < max_frames:\r\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, max_frames - num_frames))\r\n",
    "    elif num_frames > max_frames:\r\n",
    "        waveform = waveform.narrow(dim=1, start=0, length=max_frames)\r\n",
    "\r\n",
    "    return waveform\r\n",
    "\r\n",
    "transforms = nn.Sequential(\r\n",
    "    aT.Resample(original_rate, sample_rate),\r\n",
    "    aT.MFCC(sample_rate=sample_rate, n_mfcc=64),\r\n",
    "    aT.AmplitudeToDB(),\r\n",
    ")\r\n",
    "\r\n",
    "def predict(audio_path):\r\n",
    "    waveform = audio_loader(audio_path)\r\n",
    "    inputs = transforms(waveform)\r\n",
    "\r\n",
    "    MODEL_PATH = './IE643_190020066_CHALLENGE_MODEL.pt'\r\n",
    "    model = torch.load(MODEL_PATH)\r\n",
    "    model.to(device)\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    inputs = inputs.unsqueeze(1)\r\n",
    "    inputs = inputs.to(device)\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        output = model(inputs)\r\n",
    "\r\n",
    "        output = output.squeeze()\r\n",
    "        output =  F.softmax(output, dim=-1)\r\n",
    "\r\n",
    "        accuracy, predicted = torch.max(output.data, -1)\r\n",
    "        accuracy *= 100\r\n",
    "        predicted = classes[predicted]\r\n",
    "\r\n",
    "        return predicted, accuracy\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python39\\lib\\site-packages\\torchaudio\\functional\\functional.py:432: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "AUDIO_PATH = './dataset/2/430816.wav'\r\n",
    "\r\n",
    "predicted, accuracy = predict(AUDIO_PATH)\r\n",
    "\r\n",
    "print(f\"Predicted '{predicted}' with {accuracy:.2f}% accuracy\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted '2' with 99.80% accuracy\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}